{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import multiprocessing  as mp\n",
    "from itertools import product\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Input, Concatenate, Lambda,LSTM,Dropout,Layer,Flatten\n",
    "from keras.layers import ConvLSTM2D,BatchNormalization,TimeDistributed,MaxPooling3D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras.losses as kl\n",
    "import pydot\n",
    "\n",
    "from sys import getsizeof\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "from functions import *\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.modules[__name__].__dict__.clear()\n",
    "# Data.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = 7*3600\n",
    "endTime = 10*3600\n",
    "dt = 30\n",
    "ncoeur = 8\n",
    "\n",
    "Data = get_time_data('data/data2/Times/fahrzeiten_soll_ist_20200105_20200111.csv')\n",
    "Data = Data.loc[Data['datum_nach'].dt.dayofweek < 5,:]\n",
    "#delete depot run\n",
    "Data = Data[~Data['fw_lang'].str.contains('DEP|Einfahrt|Ausfahrt')]\n",
    "\n",
    "\n",
    "Studied_line = 32\n",
    "# Data = Data[Data['linie']<100]\n",
    "Data = Data.sort_values(by ='halt_diva_nach')\n",
    "Data['ID'] = 1000000000*Data['richtung']+ 100000*Data['linie']+Data['halt_diva_nach']\n",
    "Data = Data.sort_values(by ='ID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection\n",
    "### Stops\n",
    "Select the 3 lateness (travel time, stops and total ) for every stops every 30s, if no new bus came, the last one is kept. It was first thought to take as time step the updating of the bus lateness, but as we now have multiple bus it does not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "def features_selector(Data_d):\n",
    "    Data_d = pd.DataFrame({\n",
    "        'Delta_stops'  :(Data_d['ist_ab_nach']-Data_d['ist_an_nach1']-Data_d['soll_ab_nach']+Data_d['soll_an_nach'])/(\n",
    "                        Data_d['soll_ab_nach']-Data_d['soll_an_nach']),\n",
    "        'Delta_trip'   :(Data_d['ist_an_nach1']-Data_d['ist_ab_von']-Data_d['soll_an_nach']+Data_d['soll_ab_von'])/(\n",
    "                          Data_d['soll_an_nach']-Data_d['soll_an_von'])  ,\n",
    "        'Tot_lat'      :Data_d['ist_ab_nach']-Data_d['soll_ab_nach'],\n",
    "        'ID'           :Data_d['ID'],\n",
    "        'time'         :Data_d['ist_ab_nach']})\n",
    "\n",
    "    colname = [np.repeat(Data['ID'].unique(),3),np.resize(['Delta_stops','Delta_trip','Tot_lat'\n",
    "                                                             ],3*Data['ID'].unique().shape[0])]\n",
    "\n",
    "    out = pd.DataFrame(index = range(startTime,endTime,dt) ,columns= colname)\n",
    "    t_last = startTime\n",
    "\n",
    "    Data_t = Data_d.loc[(Data_d['time'] < t_last) ,['Delta_stops','Delta_trip','Tot_lat','ID']]\n",
    "\n",
    "    out.loc[t_last,idx[Data_t['ID'].values,:]] = Data_t.groupby('ID').last().values.ravel()\n",
    "\n",
    "    for t in range(startTime,endTime,dt):\n",
    "        Data_t = Data_d.loc[(Data_d['time'] > t_last) &(Data_d['time'] <= t),['Delta_stops','Delta_trip','Tot_lat','ID']]\n",
    "\n",
    "        out.loc[t] = out.loc[t_last]\n",
    "        out.loc[t,idx[Data_t['ID'].values,:]] = Data_t.groupby('ID').mean().values.ravel()\n",
    "\n",
    "        t_last = t\n",
    "        \n",
    "    return np.array([out.loc[:,idx[:,'Delta_stops']].to_numpy(),out.loc[:,idx[:,'Delta_trip']].to_numpy(),out.loc[:,idx[:,'Tot_lat']].to_numpy()])   \n",
    "    del(Data_t,Data_d,out)\n",
    "\n",
    "pool = mp.Pool(ncoeur) \n",
    "i = 0\n",
    "for day in Data['datum_nach'].unique():\n",
    "    if i == 0:\n",
    "        splitData = list([Data.loc[Data['datum_nach'] == day,:]])\n",
    "    else:\n",
    "        splitData.append(Data.loc[Data['datum_nach'] == day,:])\n",
    "    i+=1\n",
    "    \n",
    "FrameT = np.array(pool.map(features_selector,splitData),np.float32)#np.array(,np.float32)\n",
    "pool.close()\n",
    "pool.join() # 28\n",
    "\n",
    "print('Time spent: ',time.time()-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape into (#sample , time ,features, #stop, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameT = np.moveaxis(FrameT, [0, 1, 2, 3], [0, 2, 1, 3])\n",
    "FrameT = np.expand_dims(FrameT,axis = 4)\n",
    "FrameT.shape #(5, 360, 3, 2472, 1) 1539\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus\n",
    "The bus delay for all the bus in the line is computed every 30s.  ( don't need reshape already good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_out(Data_d):\n",
    "    Data_d = splitData[0]\n",
    "    Data_d = Data_d.loc[Data_d['linie'] == Studied_line,:]\n",
    "    \n",
    "    Data_d['Tot_latness'] = Data_d['ist_ab_nach']-Data_d['soll_ab_nach']\n",
    "    \n",
    "    idBus = Data_d.loc[(Data_d['soll_ab_nach']>=startTime ) &(\n",
    "                        (Data_d['soll_ab_nach']<=endTime )\n",
    "            ) & (Data_d['halt_diva_nach'] == 1143) ,'fahrzeug'].unique()\n",
    "    \n",
    "    \n",
    "    out= pd.DataFrame(index = range(startTime,endTime,dt), columns = idBus)\n",
    "    \n",
    "    t_last = startTime\n",
    "    Data_t = Data_d.loc[(Data_d['ist_ab_nach'] < t_last),['Tot_latness','fahrzeug']]\n",
    "    out.loc[t_last].update(Data_t.groupby('fahrzeug').last()['Tot_latness'])\n",
    "\n",
    "    for t in range(startTime+dt,endTime,dt):\n",
    "        Data_t = Data_d.loc[(Data_d['ist_ab_nach'] > t_last) &(Data_d['ist_ab_nach'] <= t),['Tot_latness','fahrzeug']]\n",
    "        if Data_t['fahrzeug'].size == 0:\n",
    "            out.loc[t,:] = out.loc[t_last,:]\n",
    "        else:\n",
    "            out.loc[t,:] = out.loc[t_last,:]\n",
    "            out.loc[t,Data_t['fahrzeug'].unique()] =  Data_t.groupby('fahrzeug').mean().values.ravel()\n",
    "\n",
    "        t_last = t\n",
    "        \n",
    "        out = out.dropna(axis='columns',how='all')\n",
    "        \n",
    "    return  out.to_numpy()\n",
    "    del(Data_t,Data_d,out)\n",
    "\n",
    "pool = mp.Pool(ncoeur) \n",
    "\n",
    "out = np.array(pool.map(get_out,splitData),np.float32)\n",
    "pool.close()\n",
    "pool.join() # 28  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    ConvLSTM2D(filters=20, kernel_size=(10, 1)\n",
    "                       , padding='same', return_sequences=True\n",
    "                       , input_shape = (FrameT.shape[1],FrameT.shape[2],FrameT.shape[3],FrameT.shape[4])),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    BatchNormalization(),\n",
    "        \n",
    "    ConvLSTM2D(filters=10, kernel_size=(5, 1)\n",
    "                         ,padding='same', return_sequences=True),\n",
    "    \n",
    "    Dropout(0.1),\n",
    "    \n",
    "    BatchNormalization(),\n",
    "        \n",
    "    ConvLSTM2D(filters=10,  kernel_size=(10, 1)\n",
    "                       , padding='same', return_sequences=True),\n",
    "    Dropout(0.1),\n",
    "    BatchNormalization(),\n",
    "    ConvLSTM2D(name ='conv_lstm_4',\n",
    "                         filters = 20, kernel_size = (5, 1), \n",
    "                         padding='same',\n",
    "                         return_sequences = True),\n",
    "        \n",
    "    TimeDistributed(Flatten()),\n",
    "    \n",
    "    TimeDistributed(Dense(512,)),\n",
    "    \n",
    "    TimeDistributed(Dense(32,)),\n",
    "    \n",
    "    TimeDistributed(Dense(out.shape[2]), name='test'),\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer = RMSprop())\n",
    "model.summary()\n",
    "\n",
    "plot_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 5\n",
    "t1 = time.time()\n",
    "history = model.fit(FrameT[:4,:,:,:,:],out[:4,:,:], batch_size=\n",
    "                            batch_size,epochs=epochs,verbose=1,validation_data=(FrameT[4:5,:,:,:,:], out[4:5,:,:]))\n",
    "\n",
    "print('time spend:',t1-time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "latness_predict = model.predict(FrameT[4:5,:,:,:,:])\n",
    "print('time spend:',t1-time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs_plot = range(epochs)\n",
    "plt.figure(2)\n",
    "plt.plot(epochs_plot, loss, 'bo', label='Training loss') #val_loss\n",
    "plt.plot(epochs_plot, loss_val, 'bs', label='Validation loss') #val_loss\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(3,figsize = (12,5))\n",
    "\n",
    "# which = 3\n",
    "\n",
    "# plt.plot(latness_predict[0,:,which], label='Predict') #val_loss\n",
    "# plt.plot(out[0,:,which], label='Real') #val_loss\n",
    "\n",
    "# plt.title('Loss')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Latness')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(BatchNormalization(name = 'batch_norm_0', input_shape = (input_timesteps, num_links, 1, 1)))\n",
    "# model.add(ConvLSTM2D(name ='conv_lstm_1',\n",
    "#                          filters = 64, kernel_size = (10, 1),                       \n",
    "#                          padding = 'same', \n",
    "#                          return_sequences = True))\n",
    "\n",
    "# model.add(Dropout(0.2, name = 'dropout_1'))\n",
    "# model.add(BatchNormalization(name = 'batch_norm_1'))\n",
    "\n",
    "# model.add(ConvLSTM2D(name ='conv_lstm_2',\n",
    "#                          filters = 64, kernel_size = (5, 1), \n",
    "#                          padding='same',\n",
    "#                          return_sequences = False))\n",
    "\n",
    "# model.add(Dropout(0.1, name = 'dropout_2'))\n",
    "# model.add(BatchNormalization(name = 'batch_norm_2'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(RepeatVector(output_timesteps))\n",
    "# model.add(Reshape((output_timesteps, num_links, 1, 64)))\n",
    "\n",
    "# model.add(ConvLSTM2D(name ='conv_lstm_3',\n",
    "#                          filters = 64, kernel_size = (10, 1), \n",
    "#                          padding='same',\n",
    "#                          return_sequences = True))\n",
    "\n",
    "# model.add(Dropout(0.1, name = 'dropout_3'))\n",
    "# model.add(BatchNormalization(name = 'batch_norm_3'))\n",
    "# model.add(ConvLSTM2D(name ='conv_lstm_4',\n",
    "#                          filters = 64, kernel_size = (5, 1), \n",
    "#                          padding='same',\n",
    "#                          return_sequences = True))\n",
    "\n",
    "# model.add(TimeDistributed(Dense(units=1, name = 'dense_1', activation = 'relu')))\n",
    "#     #model.add(Dense(units=1, name = 'dense_2'))\n",
    "    \n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
